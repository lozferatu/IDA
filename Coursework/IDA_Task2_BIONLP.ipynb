{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fc4e9a-df49-45e0-98e6-ebd49cf54044",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-02T09:40:07.770692500Z",
     "start_time": "2023-07-02T09:40:07.742187400Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ec39563-772c-4acb-a00c-4a1dd573162e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# BIONLP 2004\n",
    "\n",
    "This dataset contains abstracts from MEDLINE, a database containing journal articles from fields including medicine and pharmacy. \n",
    "The data was collected by searching for the terms ‘human’, ‘blood cells’ and ‘transcription factors’, and then annotated with five entity types: DNA, protein, cell type, cell line, RNA. \n",
    "\n",
    "More information in the paper: https://aclanthology.org/W04-1213.pdf\n",
    "\n",
    "The data can be downloaded from HuggingFace: https://huggingface.co/datasets/tner/bionlp2004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc89a2e6-3882-4021-9e34-dd0f919cc2bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-02T09:40:07.810699900Z",
     "start_time": "2023-07-02T09:40:07.779694500Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8e09e77-9177-4360-a684-9531dbcf543a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-02T09:40:09.084928300Z",
     "start_time": "2023-07-02T09:40:07.810199800Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Use HuggingFace's datasets library to access the financial_phrasebank dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d353ede4-863a-4378-976a-4f5607cd7a68",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-07-02T09:40:11.976133100Z",
     "start_time": "2023-07-02T09:40:09.121935Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset bio_nlp2004 (./data_cache\\tner___bio_nlp2004\\bionlp2004\\1.0.0\\9f41d3f0270b773c2762dee333ae36c29331e2216114a57081f77639fdb5e904)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f7a71885959a4efbb09e7af0b878faf2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset is a dictionary with 3 splits: \n",
      "\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['tokens', 'tags'],\n",
      "        num_rows: 16619\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['tokens', 'tags'],\n",
      "        num_rows: 1927\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['tokens', 'tags'],\n",
      "        num_rows: 3856\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\n",
    "    \"tner/bionlp2004\", \n",
    "    cache_dir='./data_cache'\n",
    ")\n",
    "\n",
    "print(f'The dataset is a dictionary with {len(dataset)} splits: \\n\\n{dataset}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75b64ae-f9f9-454f-9849-ef77d684dd3e",
   "metadata": {},
   "source": [
    "The dataset is already split into train, validation and test. It may be useful to reformat the DatasetDict object into lists of sentences and tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e7c8c63-c92e-48c8-8563-44e9f472e158",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-02T09:40:12.123160Z",
     "start_time": "2023-07-02T09:40:11.995137700Z"
    }
   },
   "outputs": [],
   "source": [
    "#dataset['train'][1]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "423b1fe9-4c8b-47c2-b79b-f460e8cc7112",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-02T09:40:16.388403500Z",
     "start_time": "2023-07-02T09:40:12.124159900Z"
    }
   },
   "outputs": [],
   "source": [
    "train_sentences_ner = [item['tokens'] for item in dataset['train']]\n",
    "train_labels_ner = [[str(tag) for tag in item['tags']] for item in dataset['train']]\n",
    "\n",
    "val_sentences_ner = [item['tokens'] for item in dataset['validation']]\n",
    "val_labels_ner = [[str(tag) for tag in item['tags']] for item in dataset['validation']]\n",
    "\n",
    "test_sentences_ner = [item['tokens'] for item in dataset['test']]\n",
    "test_labels_ner = [[str(tag) for tag in item['tags']] for item in dataset['test']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4da7896a-2dc0-4985-8627-48c77834f599",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-02T09:40:16.581945200Z",
     "start_time": "2023-07-02T09:40:16.397405900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training sentences = 16619\n",
      "Number of validation sentences = 1927\n",
      "Number of test sentences = 3856\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of training sentences = {len(train_sentences_ner)}')\n",
    "print(f'Number of validation sentences = {len(val_sentences_ner)}')\n",
    "print(f'Number of test sentences = {len(test_sentences_ner)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d000688-9fbb-4ea3-a95c-becf496ed43f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-02T09:40:16.731471600Z",
     "start_time": "2023-07-02T09:40:16.564942Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What does one instance look like from the training set? \n",
      "\n",
      "['Hence', ',', 'PPAR', 'can', 'positively', 'or', 'negatively', 'influence', 'TH', 'action', 'depending', 'on', 'TRE', 'structure', 'and', 'THR', 'isotype', '.']\n",
      "...and here is its corresponding label \n",
      "\n",
      "['0', '0', '3', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '3', '4', '0']\n"
     ]
    }
   ],
   "source": [
    "print(f'What does one instance look like from the training set? \\n\\n{train_sentences_ner[234]}')\n",
    "print(f'...and here is its corresponding label \\n\\n{train_labels_ner[234]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c293ad5-29d4-4f5f-9213-a37ed2853830",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-02T09:40:17.010519600Z",
     "start_time": "2023-07-02T09:40:16.737972Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique labels: ['0' '1' '10' '2' '3' '4' '5' '6' '7' '8' '9']\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of unique labels: {np.unique(np.concatenate(train_labels_ner))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3fc291-2394-49f4-99b4-9ba6e32680fe",
   "metadata": {},
   "source": [
    "These are the tags used to annotate the entities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "251f5652-afe6-4030-94e6-bf91379b34e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-02T09:40:17.202050Z",
     "start_time": "2023-07-02T09:40:17.017021800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'O', 1: 'B-DNA', 2: 'I-DNA', 3: 'B-protein', 4: 'I-protein', 5: 'B-cell_type', 6: 'I-cell_type', 7: 'B-cell_line', 8: 'I-cell_line', 9: 'B-RNA', 10: 'I-RNA'}\n"
     ]
    }
   ],
   "source": [
    "# mapping from labels to the tags\n",
    "\n",
    "id2label = {\n",
    "    \"O\": 0,\n",
    "    \"B-DNA\": 1,\n",
    "    \"I-DNA\": 2,\n",
    "    \"B-protein\": 3,\n",
    "    \"I-protein\": 4,\n",
    "    \"B-cell_type\": 5,\n",
    "    \"I-cell_type\": 6,\n",
    "    \"B-cell_line\": 7,\n",
    "    \"I-cell_line\": 8,\n",
    "    \"B-RNA\": 9,\n",
    "    \"I-RNA\": 10\n",
    "}\n",
    "\n",
    "label2id = {v:k for k, v in id2label.items()}\n",
    "print(label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '7', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '3', '0', '0', '0', '0', '0', '0', '0', '0', '0']\n"
     ]
    }
   ],
   "source": [
    "print(train_labels_ner[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T09:40:17.346233700Z",
     "start_time": "2023-07-02T09:40:17.185046700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e60b82e0-c93d-4bf3-af10-5db0e0423c5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-02T09:40:17.582774Z",
     "start_time": "2023-07-02T09:40:17.354235300Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# convert label ref from string to integer label\n",
    "int_train_labels = []\n",
    "for sent in train_labels_ner:\n",
    "    sent = list(map(int, sent)) \n",
    "    int_train_labels.append(sent)\n",
    "    # print(sent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0354cac2-1496-4571-bb6e-91518009f7e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-02T09:40:17.811492500Z",
     "start_time": "2023-07-02T09:40:17.587775800Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# working int to label\n",
    "train_lab_full = []\n",
    "\n",
    "# convert list of label indexes to label string value from label3id lookup\n",
    "for vector in int_train_labels:\n",
    "    #vector = list(map(int, vector)) \n",
    "    #print(sent)\n",
    "    sent_labels = []\n",
    "    for label in vector:\n",
    "        converted  = label2id[label]\n",
    "        sent_labels.append(converted)\n",
    "        #print(converted)\n",
    "        #res = list(zip(train_sentences_ner, train_labels_ner[idx]))\n",
    "        #train_set.append(res)\n",
    "    train_lab_full.append(list(sent_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e7aa3b6-fdb7-4217-a8d2-3ac82de3a56f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-02T09:40:18.007221400Z",
     "start_time": "2023-07-02T09:40:17.818993600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n",
      "['O', 'B-protein', 'O', 'O', 'O', 'O', 'O', 'O', 'B-protein', 'I-protein', 'O', 'O', 'O', 'O', 'B-protein', 'I-protein', 'O', 'O', 'O', 'O', 'B-protein', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "36\n",
      "['0', '3', '0', '0', '0', '0', '0', '0', '3', '4', '0', '0', '0', '0', '3', '4', '0', '0', '0', '0', '3', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0']\n"
     ]
    }
   ],
   "source": [
    "# Check lists correspond\n",
    "print(len(train_lab_full[1]))\n",
    "print(train_lab_full[1])\n",
    "print(len(train_labels_ner[1]))\n",
    "print(train_labels_ner[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "#train_sentences_ner[1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T09:40:18.152048Z",
     "start_time": "2023-07-02T09:40:17.989718700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef61c99b-01c8-4b54-aaa0-d307edc75c20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-02T09:40:18.464107300Z",
     "start_time": "2023-07-02T09:40:18.160049400Z"
    }
   },
   "outputs": [],
   "source": [
    "# working zip\n",
    "train_set = [list(zip(sentence, train_lab_full[idx])) for idx, sentence in enumerate(train_sentences_ner)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "#train_set[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T09:55:18.049330800Z",
     "start_time": "2023-07-02T09:55:17.818914700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# convert test labels from string to integer label\n",
    "int_val_labels = []\n",
    "for sent in val_labels_ner:\n",
    "    sent = list(map(int, sent))\n",
    "    int_val_labels.append(sent)\n",
    "    #print(sent)\n",
    "# working int to label\n",
    "val_lab_full = []\n",
    "\n",
    "for vector in int_val_labels:\n",
    "    #vector = list(map(int, vector))\n",
    "    #print(sent)\n",
    "    sent_labels = []\n",
    "    for label in vector:\n",
    "        converted = label2id[label]\n",
    "        sent_labels.append(converted)\n",
    "        #print(converted)\n",
    "        #res = list(zip(train_sentences_ner, train_labels_ner[idx]))\n",
    "        #train_set.append(res)\n",
    "    val_lab_full.append(list(sent_labels))\n",
    "\n",
    "val_set = [list(zip(sentence, val_lab_full[idx])) for idx, sentence in enumerate(val_sentences_ner)]\n",
    "# example\n",
    "#val_set[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T09:40:18.823679500Z",
     "start_time": "2023-07-02T09:40:18.640137900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T09:40:18.846683200Z",
     "start_time": "2023-07-02T09:40:18.833682300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e007294-cab0-4117-990f-0d3dea1b33fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-02T09:40:19.051221600Z",
     "start_time": "2023-07-02T09:40:18.854184600Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert test labels from string to integer label\n",
    "int_test_labels = []\n",
    "for sent in test_labels_ner:\n",
    "    sent = list(map(int, sent)) \n",
    "    int_test_labels.append(sent)\n",
    "    #print(sent)\n",
    "\n",
    "# working int to label\n",
    "test_lab_full = []\n",
    "\n",
    "for vector in int_test_labels:\n",
    "    #vector = list(map(int, vector))\n",
    "    #print(sent)\n",
    "    sent_labels = []\n",
    "    for label in vector:\n",
    "        converted  = label2id[label]\n",
    "        sent_labels.append(converted)\n",
    "        #print(converted)\n",
    "        #res = list(zip(train_sentences_ner, train_labels_ner[idx]))\n",
    "        #train_set.append(res)\n",
    "    test_lab_full.append(list(sent_labels))\n",
    "\n",
    "test_set = [list(zip(sentence, test_lab_full[idx])) for idx, sentence in enumerate(test_sentences_ner)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93874e80-fde6-4c08-a214-5b7389656d7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-02T09:40:19.236765Z",
     "start_time": "2023-07-02T09:40:19.059223Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_sentences_ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0eda321-8c5f-4c52-8929-fe1eee365c22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-02T09:40:19.255268200Z",
     "start_time": "2023-07-02T09:40:19.226264100Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "# Train a CRF NER tagger\n",
    "def train_CRF_NER_tagger(train_set):\n",
    "    ### WRITE YOUR OWN CODE HERE\n",
    "    tagger = nltk.tag.CRFTagger()\n",
    "    tagger.train(train_set, 'model.crf.tagger')\n",
    "    return tagger  # return the trained model\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T09:41:46.063435800Z",
     "start_time": "2023-07-02T09:40:19.251267400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# train tagger on train_set\n",
    "tagger = train_CRF_NER_tagger(train_set)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def extract_spans(tagged_sents):\n",
    "    \"\"\"\n",
    "    Extract a list of tagged spans for each named entity type,\n",
    "    where each span is represented by a tuple containing the\n",
    "    start token and end token indexes.\n",
    "\n",
    "    returns: a dictionary containing a list of spans for each entity type.\n",
    "    \"\"\"\n",
    "    spans = {}\n",
    "\n",
    "    for sidx, sent in enumerate(tagged_sents):\n",
    "        start = -1\n",
    "        entity_type = None\n",
    "        for i, (tok, lab) in enumerate(sent):\n",
    "            if 'B-' in lab:\n",
    "                start = i\n",
    "                end = i + 1\n",
    "                entity_type = lab[2:]\n",
    "            elif 'I-' in lab:\n",
    "                end = i + 1\n",
    "            elif lab == 'O' and start >= 0:\n",
    "\n",
    "                if entity_type not in spans:\n",
    "                    spans[entity_type] = []\n",
    "\n",
    "                spans[entity_type].append((start, end, sidx))\n",
    "                start = -1\n",
    "        # Sometimes an I-token is the last token in the sentence, so we still have to add the span to the list\n",
    "        if start >= 0:\n",
    "            if entity_type not in spans:\n",
    "                spans[entity_type] = []\n",
    "\n",
    "            spans[entity_type].append((start, end, sidx))\n",
    "\n",
    "    return spans\n",
    "\n",
    "\n",
    "def cal_span_level_f1(test_sents, test_sents_with_pred):\n",
    "    # get a list of spans from the test set labels\n",
    "    gold_spans = extract_spans(test_sents)\n",
    "\n",
    "    # get a list of spans predicted by our tagger\n",
    "    pred_spans = extract_spans(test_sents_with_pred)\n",
    "\n",
    "    # compute the metrics for each class:\n",
    "    f1_per_class = []\n",
    "\n",
    "    ne_types = gold_spans.keys()  # get the list of named entity types (not the tags)\n",
    "\n",
    "    for ne_type in ne_types:\n",
    "        # compute the confusion matrix\n",
    "        true_pos = 0\n",
    "        false_pos = 0\n",
    "\n",
    "        for span in pred_spans[ne_type]:\n",
    "            if span in gold_spans[ne_type]:\n",
    "                true_pos += 1\n",
    "            else:\n",
    "                false_pos += 1\n",
    "\n",
    "        false_neg = 0\n",
    "        for span in gold_spans[ne_type]:\n",
    "            if span not in pred_spans[ne_type]:\n",
    "                false_neg += 1\n",
    "\n",
    "        if true_pos + false_pos == 0:\n",
    "            precision = 0\n",
    "        else:\n",
    "            precision = true_pos / float(true_pos + false_pos)\n",
    "\n",
    "        if true_pos + false_neg == 0:\n",
    "            recall = 0\n",
    "        else:\n",
    "            recall = true_pos / float(true_pos + false_neg)\n",
    "\n",
    "        if precision + recall == 0:\n",
    "            f1 = 0\n",
    "        else:\n",
    "            f1 = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "        f1_per_class.append(f1)\n",
    "        print(f'F1 score for class {ne_type} = {f1}')\n",
    "\n",
    "    print(f'Macro-average f1 score = {np.mean(f1_per_class)}')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T09:41:46.315461400Z",
     "start_time": "2023-07-02T09:41:46.065936100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Baseline Performance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# predict tags for validation set\n",
    "predicted_tags = tagger.tag_sents(val_sentences_ner)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T09:41:46.812021500Z",
     "start_time": "2023-07-02T09:41:46.320461300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for class DNA = 0.5804387568555759\n",
      "F1 score for class protein = 0.7284813362877108\n",
      "F1 score for class cell_type = 0.630272952853598\n",
      "F1 score for class cell_line = 0.5380952380952381\n",
      "F1 score for class RNA = 0.6495726495726495\n",
      "Macro-average f1 score = 0.6253721867329545\n"
     ]
    }
   ],
   "source": [
    "# performance in predicting the validation set labels\n",
    "cal_span_level_f1(val_set, predicted_tags)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T09:41:47.306605900Z",
     "start_time": "2023-07-02T09:41:46.817021400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "span_dict = extract_spans(train_set)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T10:11:08.215430300Z",
     "start_time": "2023-07-02T10:11:07.919368500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "(13, 14, 0)"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "span_dict['protein'][0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T10:11:30.561295900Z",
     "start_time": "2023-07-02T10:11:30.322757200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('IL-2', 'B-DNA'), ('gene', 'I-DNA'), ('expression', 'O'), ('and', 'O'), ('NF-kappa', 'B-protein'), ('B', 'I-protein'), ('activation', 'O'), ('through', 'O'), ('CD28', 'B-protein'), ('requires', 'O'), ('reactive', 'O'), ('oxygen', 'O'), ('production', 'O'), ('by', 'O'), ('5-lipoxygenase', 'B-protein'), ('.', 'O')]\n"
     ]
    }
   ],
   "source": [
    "print(val_set[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T09:41:47.898209900Z",
     "start_time": "2023-07-02T09:41:47.656167600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "def mis_tagged_spans(test_sents, test_sents_with_pred):\n",
    "    \"\"\"\n",
    "    Function to compare true spans and predicted spans.\n",
    "\n",
    "    Args:\n",
    "    test_sents: The sentences with true tags. Each sentence is a list of tuples (token, tag).\n",
    "    test_sents_with_pred: The sentences with predicted tags from the model. Each sentence is a list of tuples (token, tag).\n",
    "\n",
    "    Returns:\n",
    "    A dictionary where each key is an entity type, and each value is a list of mis-tagged spans.\n",
    "    Each mis-tagged span is a tuple (token_list, true_label, pred_label).\n",
    "    \"\"\"\n",
    "\n",
    "    # get a list of spans from the test set labels\n",
    "    gold_spans = extract_spans(test_sents)\n",
    "\n",
    "    # get a list of spans predicted by our tagger\n",
    "    pred_spans = extract_spans(test_sents_with_pred)\n",
    "\n",
    "    mis_tagged = {}\n",
    "    for entity_type in gold_spans.keys():\n",
    "        gold_spans_type = set(gold_spans[entity_type])\n",
    "        pred_spans_type = set(pred_spans.get(entity_type, []))\n",
    "\n",
    "        # Find spans which are in gold but not in prediction (false negatives)\n",
    "        for span in gold_spans_type.difference(pred_spans_type):\n",
    "            start, end, sent_idx = span\n",
    "            tokens = test_sents[sent_idx][0][start:end]  # extract tokens using the span\n",
    "            mis_tagged.setdefault(entity_type, []).append((tokens, entity_type, 'O'))\n",
    "\n",
    "        # Find spans which are in prediction but not in gold (false positives)\n",
    "        for span in pred_spans_type.difference(gold_spans_type):\n",
    "            start, end, sent_idx = span\n",
    "            tokens = test_sents_with_pred[sent_idx][0][start:end]  # extract tokens using the span\n",
    "            mis_tagged.setdefault(entity_type, []).append((tokens, 'O', entity_type))\n",
    "\n",
    "    return mis_tagged"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T10:29:45.016041700Z",
     "start_time": "2023-07-02T10:29:44.772492400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "# performance in predicting the validation set labels\n",
    "mis_tagged_dict = mis_tagged_spans(val_set, predicted_tags)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T10:29:47.058655300Z",
     "start_time": "2023-07-02T10:29:46.804238500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['DNA', 'protein', 'cell_type', 'cell_line', 'RNA'])"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mis_tagged_dict.keys()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T10:29:48.312494100Z",
     "start_time": "2023-07-02T10:29:48.075953800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "[((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n (('O',), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n (('HS', 'B-DNA'), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n (('O',), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n (('O',), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n (('O',), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n (('O',), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n (('alpha', 'B-DNA'), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n (('HS', 'B-DNA'), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n (('O',), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n (('CIITA',), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O'),\n ((), 'DNA', 'O')]"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mis_tagged_dict['DNA'][0:100]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T10:32:07.052189400Z",
     "start_time": "2023-07-02T10:32:06.800618400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "[('IL-2', 'B-DNA'),\n ('gene', 'I-DNA'),\n ('expression', 'O'),\n ('and', 'O'),\n ('NF-kappa', 'B-protein'),\n ('B', 'I-protein'),\n ('activation', 'O'),\n ('through', 'O'),\n ('CD28', 'B-protein'),\n ('requires', 'O'),\n ('reactive', 'O'),\n ('oxygen', 'O'),\n ('production', 'O'),\n ('by', 'O'),\n ('5-lipoxygenase', 'B-protein'),\n ('.', 'O')]"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_set[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T10:31:32.748789400Z",
     "start_time": "2023-07-02T10:31:32.527250500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "data_analytics",
   "language": "python",
   "display_name": "data_analytics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
